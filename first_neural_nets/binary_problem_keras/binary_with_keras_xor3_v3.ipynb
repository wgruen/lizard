{"cells":[{"cell_type":"markdown","metadata":{"id":"7j89y82bQ9yP"},"source":["# mount to Google Drive\n","\n","---\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"lf6cGx5PRHCQ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"390478a0-1a5e-4844-b931-4ceea13864f5","executionInfo":{"status":"ok","timestamp":1644893360867,"user_tz":300,"elapsed":24266,"user":{"displayName":"Wolfgang Gruen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01742609913198784862"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-02-15 02:48:56--  https://raw.githubusercontent.com/wgruen/lizard/master/mount_gdrive.ipynb\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 10889 (11K) [text/plain]\n","Saving to: ‘mount_gdrive.ipynb’\n","\n","\rmount_gdrive.ipynb    0%[                    ]       0  --.-KB/s               \rmount_gdrive.ipynb  100%[===================>]  10.63K  --.-KB/s    in 0s      \n","\n","2022-02-15 02:48:56 (82.0 MB/s) - ‘mount_gdrive.ipynb’ saved [10889/10889]\n","\n","Mounted at /content/drive\n","drive  mount_gdrive.ipynb  sample_data\n","/content\n","physical devises\n","[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n","tensorflow version\n","2.7.0\n","keras version\n","2.7.0\n","Tue Feb 15 02:49:20 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P0    25W / 250W |      2MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","Your runtime has 13.6 gigabytes of available RAM\n","\n","Not using a high-RAM runtime\n"]}],"source":["!wget -O mount_gdrive.ipynb https://raw.githubusercontent.com/wgruen/lizard/master/mount_gdrive.ipynb\n","\n","#!ls\n","%run mount_gdrive.ipynb"]},{"cell_type":"markdown","metadata":{"id":"8Y3t5rdxLuob"},"source":["# Overview of the results\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"JZwrX-aqL3H2"},"source":["## Training Data\n","The machine with version 3 does uses the matrix below to train the machine for the exclusive OR function.\n","\n","    training_data_embedded_v2: [    \n","        [0.04,  0.03,  0.07,  0.01],\n","        [0.01,  0.03,  0.95,  0.99],\n","        [0.04,  0.96,  0.01,  0.99],\n","        [0.98,  0.04,  0.02,  0.99],\n","        [0.96,  0.97,  0.98,  0.01]\n","    ]\n","\n","I tried with 3 to 8 neurons in the first hidden layer and 0 to 3 neurons in the second hidden layer. Also I tried batch sizes of 4 and 32, and learning rates of 0.01, 0.001 and 0.0001.\n","After 7000 epochs, the learning reate was divided by 10. \n","\n","For early_stopping these were the parameters:\n","    monitor: 'val_loss'\n","    patience: 40000\n","    verbose: 0\n","    min_delta: 1e-8\n","\n","The best results where with one combination, which is 7 neruons in the first hidden layer, and 2 neurons in the second hidden layer, and a learning rate of 0.01 (which was reduced to 0.001 after 700 epochs and a batch size of 32.\n","\n","There is one data point for which the machine is not trained. New training will start with data data  point:\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"yJFHpIDtUk_f"},"source":["# Predit with the machine\n","\n","---\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"1b9v8h2_Uh9b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644893382735,"user_tz":300,"elapsed":21874,"user":{"displayName":"Wolfgang Gruen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01742609913198784862"}},"outputId":"b0dc751d-91c5-42d3-ce5c-bc8261af35f9"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-02-15 02:49:20--  https://raw.githubusercontent.com/wgruen/lizard/master/get_gpu.ipynb\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 10864 (11K) [text/plain]\n","Saving to: ‘get_gpu.ipynb’\n","\n","get_gpu.ipynb       100%[===================>]  10.61K  --.-KB/s    in 0s      \n","\n","2022-02-15 02:49:20 (74.5 MB/s) - ‘get_gpu.ipynb’ saved [10864/10864]\n","\n","physical devises\n","[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n","tensorflow version\n","2.7.0\n","keras version\n","2.7.0\n","Tue Feb 15 02:49:20 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P0    26W / 250W |      2MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","Found GPU at: /device:GPU:0\n","Your runtime has 13.6 gigabytes of available RAM\n","\n","Not using a high-RAM runtime\n","/root\n","/content/drive/MyDrive/colab_wolfs_git_clones/lizard\n","/content/drive/MyDrive/colab_wolfs_git_clones/lizard/first_neural_nets/binary_problem_keras\n","Collecting reportlab\n","  Downloading reportlab-3.6.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n","\u001b[K     |████████████████████████████████| 2.8 MB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: pillow>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from reportlab) (7.1.2)\n","Installing collected packages: reportlab\n","Successfully installed reportlab-3.6.6\n","not connected to a TPU\n","xor3_v3--ep-100000--i-3--hl1-4--hl2-0--lr-0.01--bs-32\ttotal_error_sum: \t[2.576083]\n","\n","not connected to a TPU\n","xor3_v3--ep-100000--i-3--hl1-4--hl2-0--lr-0.001--bs-32\ttotal_error_sum: \t[1.69010274]\n","\n","not connected to a TPU\n","xor3_v3--ep-100000--i-3--hl1-4--hl2-2--lr-0.01--bs-32\ttotal_error_sum: \t[8.42742989]\n","\n","not connected to a TPU\n","xor3_v3--ep-100000--i-3--hl1-4--hl2-2--lr-0.001--bs-32\ttotal_error_sum: \t[4.58917594]\n","\n","not connected to a TPU\n","WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6c15e5cf80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","xor3_v3--ep-100000--i-3--hl1-7--hl2-0--lr-0.01--bs-32\ttotal_error_sum: \t[5.91098711]\n","\n","not connected to a TPU\n","WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6c15f54200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","xor3_v3--ep-100000--i-3--hl1-7--hl2-0--lr-0.001--bs-32\ttotal_error_sum: \t[3.6390245]\n","\n","not connected to a TPU\n","xor3_v3--ep-100000--i-3--hl1-7--hl2-2--lr-0.01--bs-32\ttotal_error_sum: \t[5.84637076]\n","\n","not connected to a TPU\n","xor3_v3--ep-100000--i-3--hl1-7--hl2-2--lr-0.001--bs-32\ttotal_error_sum: \t[5.45630097]\n","\n","Empty DataFrame\n","Columns: []\n","Index: []\n"]}],"source":["# run python code\n","exit()  # exit runtime, so it restarts the runtime session\n","\n","!wget -O get_gpu.ipynb https://raw.githubusercontent.com/wgruen/lizard/master/get_gpu.ipynb\n","\n","#!ls\n","#!cat mount_gdrive.ipynb\n","%run get_gpu.ipynb\n","\n","%cd\n","%cd \"/content/drive/MyDrive/colab_wolfs_git_clones/lizard\"\n","#!ls \n","#!pwd\n","\n","%cd \"first_neural_nets/binary_problem_keras\"\n","#!ls\n","#!pwd\n","\n","!pip install reportlab\n","%run predict_machine.py -i config/logical_xor3_v3.configuration.keras.yaml"]},{"cell_type":"markdown","metadata":{"id":"gYYLbBFGQtl8"},"source":["# Train machine\n","\n","---\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3vKpojyITuWG","outputId":"bcc90d0e-6414-444d-8d21-c047d51c5567"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-02-15 02:49:42--  https://raw.githubusercontent.com/wgruen/lizard/master/get_gpu.ipynb\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 10864 (11K) [text/plain]\n","Saving to: ‘get_gpu.ipynb’\n","\n","\rget_gpu.ipynb         0%[                    ]       0  --.-KB/s               \rget_gpu.ipynb       100%[===================>]  10.61K  --.-KB/s    in 0.001s  \n","\n","2022-02-15 02:49:42 (17.4 MB/s) - ‘get_gpu.ipynb’ saved [10864/10864]\n","\n","physical devises\n","[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n","tensorflow version\n","2.7.0\n","keras version\n","2.7.0\n","Tue Feb 15 02:49:42 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P0    32W / 250W |    451MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n","Found GPU at: /device:GPU:0\n","Your runtime has 13.6 gigabytes of available RAM\n","\n","Not using a high-RAM runtime\n","/root\n","/content/drive/MyDrive/colab_wolfs_git_clones/lizard\n","/content/drive/MyDrive/colab_wolfs_git_clones/lizard/first_neural_nets/binary_problem_keras\n","Requirement already satisfied: reportlab in /usr/local/lib/python3.7/dist-packages (3.6.6)\n","Requirement already satisfied: pillow>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from reportlab) (7.1.2)\n","not connected to a TPU\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 4)                 16        \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 5         \n","                                                                 \n","=================================================================\n","Total params: 21\n","Trainable params: 21\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["\n","# run python code\n","exit()  # exit runtime, so it restarts the runtime session\n","\n","\n","!wget -O get_gpu.ipynb https://raw.githubusercontent.com/wgruen/lizard/master/get_gpu.ipynb\n","\n","#!ls\n","#!cat mount_gdrive.ipynb\n","%run get_gpu.ipynb\n","\n","%cd\n","%cd \"/content/drive/MyDrive/colab_wolfs_git_clones/lizard\"\n","#!ls \n","#!pwd\n","\n","%cd \"first_neural_nets/binary_problem_keras\"\n","#!ls\n","#!pwd\n","\n","!pip install reportlab\n","%run train_machine.py -i config/logical_xor3_v3.configuration.keras.yaml\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["JZwrX-aqL3H2","gYYLbBFGQtl8"],"name":"binary_with_keras_xor3_v3.ipynb","provenance":[{"file_id":"/v2/external/notebooks/intro.ipynb","timestamp":1639750401434}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}