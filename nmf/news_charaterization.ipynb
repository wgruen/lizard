{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import exp, array, random, dot, round\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.platypus import *\n",
    "from reportlab.lib import colors\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.lib.styles import ParagraphStyle, getSampleStyleSheet\n",
    "\n",
    "styles = getSampleStyleSheet()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/topic-modeling-for-the-new-york-times-news-dataset-1f643e15caac\n",
    "\n",
    "Topic Modeling for The New York Times News Dataset\n",
    "Nonnegative Matrix Factorization\n",
    "Author: Moorissa Tjokro\n",
    "\n",
    "a. Plot the divergence objective for learning 25 topics as a function of iteration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This file contains index of words appearing documents.\n",
    "Each line presents a document\n",
    "In each line, there are pairs with two data points. The first data point is an index to a word in the vocabulary file. The second data point is the the number of times that specific word appears in the document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/nyt_data.txt') as f:\n",
    "    documents = f.readlines()\n",
    "documents = [x.strip().strip('\\n').strip(\"'\") for x in documents] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the Vocabulary (dictionary)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This file contains vocabs. Each row has one vocab: \n",
    "Index <space> vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/nyt_vocab.dat') as f:\n",
    "    vocabs = f.readlines()\n",
    "vocabs = [x.strip().strip('\\n').strip(\"'\") for x in vocabs] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create matrix for documents"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "create a matrix representing the documents\n",
    "x is number of vocabs\n",
    "y is number of documents\n",
    "\n",
    "Then we put the number of occurances of each vocab for each documment into the matrix\n",
    "The matric then has only the number of occurances of each vocab\n",
    "\n",
    "Each document will be represented in one column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''create matrix X'''\n",
    "numDoc = 8447\n",
    "numWord = 3012 \n",
    "X = np.zeros([numWord,numDoc])\n",
    "\n",
    "for col in range(len(documents)):\n",
    "    for row in documents[col].split(','):\n",
    "        X[int(row.split(':')[0])-1,col] = int(row.split(':')[1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Two matricies\n",
    "\n",
    "W is a matrix showing the ranking for each vocab\n",
    "x the is a row for each vocab\n",
    "y is the ranking for each vocab\n",
    "\n",
    "\n",
    "H is a matrix for document ranking \n",
    "x is the rank of each document\n",
    "Initialize them with zeros\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''randomly initialize W and H with nonnegative values'''\n",
    "rank = 25\n",
    "T = 100\n",
    "W = np.zeros([numWord,rank])\n",
    "H = np.zeros([rank,numDoc])\n",
    "\n",
    "for row in range(numWord):\n",
    "    W[row] = np.random.rand(rank)\n",
    "for row in range(rank):\n",
    "    H[row] = np.random.rand(numDoc)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "A few dot products \n",
    "\n",
    "The Transfer Matrix for vocab ranking DOT the document matrix\n",
    "\n",
    "The Matrix for vocab ranking DOT the matrix for document ranking\n",
    "\n",
    "The Transfer matrix for the previous result DOT matrix for vocab ranking\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''setting divergence penalty''' #iterate values in H, then in W\n",
    "d_iter = np.zeros(100)\n",
    "\n",
    "for iteration in range(100):\n",
    "    \n",
    "    '''iterate all values in H'''\n",
    "    m1 = np.dot(W.T,X)\n",
    "    m2 = np.dot(W,H)\n",
    "    m3 = np.dot(m2.T,W)\n",
    "    second = np.divide(m1,m3.T + 0.0000000000000001)\n",
    "\n",
    "    for k in range(rank):\n",
    "        for j in range(numDoc):\n",
    "            H[k,j] = np.multiply(H[k,j], second[k,j])\n",
    "    \n",
    "    '''iterate all values in W'''\n",
    "    n1 = np.dot(H,X.T)\n",
    "    n2 = np.dot(W,H)\n",
    "    n3 = np.dot(n2,H.T)\n",
    "    third = np.divide(n1.T,n3 + 0.0000000000000001)\n",
    "\n",
    "    for i in range(numWord):\n",
    "        for k in range(rank):\n",
    "            W[i,k] = np.multiply(W[i,k], third[i,k])\n",
    "        \n",
    "    '''plot objective function'''\n",
    "#     D = np.multiply(X, np.log(1/(n2 + 0.0000000000000001))) + n2\n",
    "#     d_iter[iteration] = np.sum(D)\n",
    "    D = np.multiply(X,np.log(n2+0.0000000000000001)) - n2\n",
    "    d_iter[iteration] = -np.sum(D)\n",
    "\n",
    "fig= plt.figure(figsize = (15,6))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.plot(range(100),d_iter[:100])\n",
    "plt.title('Plot of divergence objective in 100 iterations')\n",
    "plt.ylabel('$D(X||WH)$')\n",
    "plt.xlabel('iteration $t$')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ### b. Ten words with the largest weight.\n",
    "\n",
    "# In[502]:\n",
    "\n",
    "'''normalize each column to sum to zero'''\n",
    "W_normed = W / np.sum(W,axis=0)\n",
    "\n",
    "\n",
    "# In[511]:\n",
    "\n",
    "'''for each column of W, list the 10 words having the largest weight and show the weight'''\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.width', 120)    \n",
    "vList = []\n",
    "\n",
    "\n",
    "\n",
    "doc_summary  = SimpleDocTemplate(\"output/news_charaterization_summary.pdf\"+ \"_summary.pdf\", pagesize=letter)\n",
    "element = []\n",
    "header = Paragraph(\"\\nSummary of Analysis Run\", styles[\"Heading1\"])\n",
    "element.append(header)\n",
    "    \n",
    "\n",
    "\n",
    "for topic in range(rank):\n",
    "    v = pd.DataFrame(vocabs)\n",
    "    v[1] = W_normed[:,topic].round(6)\n",
    "    v = v.sort_values([1, 0], ascending=[0,1]).rename(index=int, columns={0: \"Topic {}\".format(topic+1), 1: \"Weight\"}).head(10)\n",
    "    v = v.reset_index(drop=True)\n",
    "    vList.append(v)\n",
    "    \n",
    "#    lista = [df.columns[:,].values.astype(str).tolist()] + df.values.tolist()\n",
    "#    t1 = Table(lista)        \n",
    "#    element.append(t1)\n",
    "    element.append(v)\n",
    "     \n",
    "\n",
    "    \n",
    "for num in [5,10,15,20,25]:\n",
    "    print('\\n',(pd.concat(vList[num-5:num], axis=1)),'\\n')\n",
    "    print(\"lineline\")\n",
    "    print(vList[num-5:num])\n",
    "    print(\"linelineline\")\n",
    "    t1 = Table(vList[num-5:num])  \n",
    "    element.append(t1)\n",
    "    t11 = vList[num-5:num]\n",
    "    print(\"t11\")\n",
    "    print(t11)\n",
    "    element.append(Table(t11))\n",
    "    \n",
    "    \n",
    "doc_summary.build(element)\n",
    "    \n",
    "# sort by standard deviation  \n",
    "#header = Paragraph(\"\\nSorted by Interquartile Range\", styles[\"Heading2\"])Analysis\n",
    "#element.append(header)\n",
    "    \n",
    "\n",
    "#df = df.sort_values(by=[\"interquartile_range\"])\n",
    "#    lista = [df.columns[:,].values.astype(str).tolist()] + df.values.tolist()\n",
    "#    t1 = Table(lista)        \n",
    "#    element.append(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
