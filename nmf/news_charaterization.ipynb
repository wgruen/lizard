{"cells":[{"cell_type":"code","source":["!wget https://raw.githubusercontent.com/wgruen/lizard/master/mount_gdrive.ipynb\n","\n","#!ls\n","%run mount_gdrive.ipynb\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"18vK3sqJIJ2Z","executionInfo":{"status":"ok","timestamp":1644799490341,"user_tz":300,"elapsed":22721,"user":{"displayName":"Wolfgang Gruen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01742609913198784862"}},"outputId":"6b438ef1-816c-4c06-fd1c-1c4d4971b79c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-02-14 00:44:26--  https://raw.githubusercontent.com/wgruen/lizard/master/mount_gdrive.ipynb\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 10889 (11K) [text/plain]\n","Saving to: ‘mount_gdrive.ipynb’\n","\n","\rmount_gdrive.ipynb    0%[                    ]       0  --.-KB/s               \rmount_gdrive.ipynb  100%[===================>]  10.63K  --.-KB/s    in 0s      \n","\n","2022-02-14 00:44:26 (47.2 MB/s) - ‘mount_gdrive.ipynb’ saved [10889/10889]\n","\n","Mounted at /content/drive\n","drive  mount_gdrive.ipynb  sample_data\n","/content\n","physical devises\n","[]\n","tensorflow version\n","2.7.0\n","keras version\n","2.7.0\n","/bin/bash: nvidia-smi: command not found\n","Your runtime has 13.6 gigabytes of available RAM\n","\n","Not using a high-RAM runtime\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lnJ46AX9v68M","colab":{"base_uri":"https://localhost:8080/","height":590},"executionInfo":{"status":"ok","timestamp":1644799537020,"user_tz":300,"elapsed":3277,"user":{"displayName":"Wolfgang Gruen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01742609913198784862"}},"outputId":"fd9c1235-8b43-4f4a-8c30-f5d31a252fe1","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-02-14 00:45:32--  https://raw.githubusercontent.com/wgruen/lizard/master/get_gpu.ipynb\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 10864 (11K) [text/plain]\n","Saving to: ‘get_gpu.ipynb’\n","\n","\rget_gpu.ipynb         0%[                    ]       0  --.-KB/s               \rget_gpu.ipynb       100%[===================>]  10.61K  --.-KB/s    in 0s      \n","\n","2022-02-14 00:45:32 (91.8 MB/s) - ‘get_gpu.ipynb’ saved [10864/10864]\n","\n","physical devises\n","[]\n","tensorflow version\n","2.7.0\n","keras version\n","2.7.0\n","/bin/bash: nvidia-smi: command not found\n"]},{"output_type":"error","ename":"SystemError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m/content/get_gpu.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_device_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'/device:GPU:0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mSystemError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU device not found'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Found GPU at: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mSystemError\u001b[0m: GPU device not found"]},{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/colab_wolfs_git_clones/lizard\n","/content/drive/MyDrive/colab_wolfs_git_clones/lizard/nmf\n"]}],"source":["# run a notebook\n","exit()  # exit runtime, so it restarts the runtime session\n","\n","\n","!wget -O get_gpu.ipynb https://raw.githubusercontent.com/wgruen/lizard/master/get_gpu.ipynb\n","\n","#!ls\n","%run get_gpu.ipynb\n","\n","%cd \"/content/drive/MyDrive/colab_wolfs_git_clones/lizard\"\n","#!ls \n","#!pwd\n","\n","%cd \"nmf\"\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xcHo9ZaMw7SY","executionInfo":{"status":"ok","timestamp":1644799497264,"user_tz":300,"elapsed":5984,"user":{"displayName":"Wolfgang Gruen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01742609913198784862"}},"outputId":"647bb0c6-a862-4e80-9465-82a27550889e","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting reportlab\n","  Downloading reportlab-3.6.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n","\u001b[K     |████████████████████████████████| 2.8 MB 7.6 MB/s \n","\u001b[?25hRequirement already satisfied: pillow>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from reportlab) (7.1.2)\n","Installing collected packages: reportlab\n","Successfully installed reportlab-3.6.6\n","/content/drive/MyDrive/colab_wolfs_git_clones/lizard/nmf\n","data  news_charaterization.ipynb  news_charaterization.py  nmf_newspaper.ipynb\n"]}],"source":["from numpy import exp, array, random, dot, round\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd \n","import os\n","\n","!pip install reportlab \n","from reportlab.pdfgen import canvas\n","from reportlab.platypus import *\n","from reportlab.lib import colors\n","from reportlab.lib.pagesizes import letter\n","from reportlab.lib.styles import ParagraphStyle, getSampleStyleSheet\n","\n","styles = getSampleStyleSheet()\n","\n","#current dir\n","cwd = os.getcwd()\n","print(cwd)\n","\n","! ls"]},{"cell_type":"markdown","metadata":{"id":"JOASe4zdw7Sb"},"source":["### Read the data "]},{"cell_type":"raw","metadata":{"id":"vtxmc8PIw7Sc"},"source":["This file contains index of words appearing documents.\n","Each line presents a document\n","In each line, there are pairs with two data points. The first data point is an index to a word in the vocabulary file. The second data point is the the number of times that specific word appears in the document.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B4Yq_m13w7Sd"},"outputs":[],"source":["with open('./data/nyt_data.txt') as f:\n","    documents = f.readlines()\n","documents = [x.strip().strip('\\n').strip(\"'\") for x in documents] "]},{"cell_type":"markdown","metadata":{"id":"opgrrsmHw7Se"},"source":["### Read the Vocabulary (dictionary)"]},{"cell_type":"raw","metadata":{"id":"LEWyRLDEw7Se"},"source":["This file contains vocabs. Each row has one vocab: \n","Index <space> vocabulary"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Psadqi3qw7Sg"},"outputs":[],"source":["with open('data/nyt_vocab.dat') as f:\n","    vocabs = f.readlines()\n","vocabs = [x.strip().strip('\\n').strip(\"'\") for x in vocabs] "]},{"cell_type":"markdown","metadata":{"id":"JF4sOt2-w7Sh"},"source":["### Create matrix for documents"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sXp8Ml2Yw7Si"},"outputs":[],"source":["'''create matrix X'''\n","numDoc = 8447\n","numWord = 3012 \n","X = np.zeros([numWord,numDoc])\n","\n","for col in range(len(documents)):\n","    for row in documents[col].split(','):\n","        X[int(row.split(':')[0])-1,col] = int(row.split(':')[1])"]},{"cell_type":"raw","metadata":{"id":"hQ_t1mMMw7Sj"},"source":["Two matricies\n","\n","W is a matrix showing the ranking for each vocab\n","x the is a row for each vocab\n","y is the ranking for each vocab\n","\n","\n","H is a matrix for document ranking \n","x is the rank of each document\n","Initialize them with zeros\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wk0Hj51Hw7Sk"},"outputs":[],"source":["'''randomly initialize W and H with nonnegative values'''\n","rank = 25\n","T = 100\n","W = np.zeros([numWord,rank])\n","H = np.zeros([rank,numDoc])\n","\n","for row in range(numWord):\n","    W[row] = np.random.rand(rank)\n","for row in range(rank):\n","    H[row] = np.random.rand(numDoc)\n","    \n","    \n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ix3qe7Baw7Sl"},"outputs":[],"source":["'''setting divergence penalty''' #iterate values in H, then in W\n","d_iter = np.zeros(100)\n","\n","for iteration in range(100):\n","    \n","    '''iterate all values in H'''\n","    m1 = np.dot(W.T,X)\n","    m2 = np.dot(W,H)\n","    m3 = np.dot(m2.T,W)\n","    second = np.divide(m1,m3.T + 0.0000000000000001)\n","\n","    for k in range(rank):\n","        for j in range(numDoc):\n","            H[k,j] = np.multiply(H[k,j], second[k,j])\n","    \n","    '''iterate all values in W'''\n","    n1 = np.dot(H,X.T)\n","    n2 = np.dot(W,H)\n","    n3 = np.dot(n2,H.T)\n","    third = np.divide(n1.T,n3 + 0.0000000000000001)\n","\n","    for i in range(numWord):\n","        for k in range(rank):\n","            W[i,k] = np.multiply(W[i,k], third[i,k])\n","        \n","    '''plot objective function'''\n","#     D = np.multiply(X, np.log(1/(n2 + 0.0000000000000001))) + n2\n","#     d_iter[iteration] = np.sum(D)\n","    D = np.multiply(X,np.log(n2+0.0000000000000001)) - n2\n","    d_iter[iteration] = -np.sum(D)\n","\n","fig= plt.figure(figsize = (15,6))\n","ax = fig.add_subplot(1,1,1)\n","ax.plot(range(100),d_iter[:100])\n","plt.title('Plot of divergence objective in 100 iterations')\n","plt.ylabel('$D(X||WH)$')\n","plt.xlabel('iteration $t$')\n","plt.show()\n","\n","\n","# ### b. Ten words with the largest weight.\n","\n","# In[502]:\n","\n","'''normalize each column to sum to zero'''\n","W_normed = W / np.sum(W,axis=0)\n","\n","\n","# In[511]:\n","\n","'''for each column of W, list the 10 words having the largest weight and show the weight'''\n","pd.set_option('display.max_rows', 50)\n","pd.set_option('display.max_columns', 50)\n","pd.set_option('display.width', 120)    \n","vList = []\n","\n","\n","if not os.path.exists(\"output\"):\n","    os.mkdir(\"output\")\n","doc_summary  = SimpleDocTemplate(\"output/news_charaterization_summary.pdf\"+ \"_summary.pdf\", pagesize=letter)\n","element = []\n","header = Paragraph(\"\\nSummary of Analysis Run\", styles[\"Heading1\"])\n","element.append(header)\n","    \n","\n","\n","for topic in range(rank):\n","    v = pd.DataFrame(vocabs)\n","    v[1] = W_normed[:,topic].round(6)\n","    v = v.sort_values([1, 0], ascending=[0,1]).rename(index=int, columns={0: \"Topic {}\".format(topic+1), 1: \"Weight\"}).head(10)\n","    v = v.reset_index(drop=True)\n","    vList.append(v)\n","    \n","#    lista = [df.columns[:,].values.astype(str).tolist()] + df.values.tolist()\n","#    t1 = Table(lista)        \n","#    element.append(t1)\n","#    element.append(v)\n","     \n","\n","    \n","for num in [5,10,15,20,25]:\n","    print('\\n',(pd.concat(vList[num-5:num], axis=1)),'\\n')\n","    print(\"lineline\")\n","    print(vList[num-5:num])\n","    print(\"linelineline\")\n","    t1 = Table(vList[num-5:num])  \n","    element.append(t1)\n","    t11 = vList[num-5:num]\n","    print(\"t11\")\n","    print(t11)\n","    element.append(Table(t11))\n","    \n","    \n","doc_summary.build(element)\n","    \n","# sort by standard deviation  \n","#header = Paragraph(\"\\nSorted by Interquartile Range\", styles[\"Heading2\"])Analysis\n","#element.append(header)\n","    \n","\n","#df = df.sort_values(by=[\"interquartile_range\"])\n","#    lista = [df.columns[:,].values.astype(str).tolist()] + df.values.tolist()\n","#    t1 = Table(lista)        \n","#    element.append(t1)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"news_charaterization.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}