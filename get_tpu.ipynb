{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"get_tpu.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOzUh/0RafEzlPSubvUSh9S"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","source":["# Print information"],"metadata":{"id":"tvBXKaCusMIZ"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"7uKG3cHUjFI4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642517276415,"user_tz":300,"elapsed":4576,"user":{"displayName":"Wolfgang Gruen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01742609913198784862"}},"outputId":"ae1a53db-f79e-4336-ebe5-6279d2481e02"},"outputs":[{"output_type":"stream","name":"stdout","text":["physical GPU devises\n","[]\n","physical TPU devises\n","[]\n","tensorflow version\n","2.7.0\n","keras version\n","2.7.0\n"]}],"source":["import tensorflow as tf\n","from tensorflow import keras as keras\n","\n","print(\"tensorflow version\")\n","print(tf.__version__)\n","print(\"keras version\")\n","print(keras.__version__)"]},{"cell_type":"markdown","source":["# Print machine capacity"],"metadata":{"id":"hNliE2zOsXIK"}},{"cell_type":"markdown","metadata":{"id":"SKQ4bH7qMGrA"},"source":["# Making the Most of your Colab Subscription\n","\n"]},{"cell_type":"markdown","metadata":{"id":"QMMqmdiYMkvi"},"source":["## Faster GPUs\n","\n","With Colab Pro you have priority access to our fastest GPUs and with Pro+ even more so. For example, you may get a T4 or P100 GPU at times when most users of standard Colab receive a slower K80 GPU. You can see what GPU you've been assigned at any time by executing the following cell.\n","\n","If the execution result of running the code cell below is \"Not connected to a GPU\", you can change the runtime by going to Runtime > Change runtime type in the menu to enable a GPU accelerator, and then re-execute the code cell."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"23TOba33L4qf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642532377336,"user_tz":300,"elapsed":21439,"user":{"displayName":"Wolfgang Gruen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01742609913198784862"}},"outputId":"46c2f8d1-30c1-4a59-a925-974e5fd2f73c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Running on TPU  ['10.65.174.202:8470']\n","INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:TPU system grpc://10.65.174.202:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:TPU system grpc://10.65.174.202:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.65.174.202:8470\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.65.174.202:8470\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Finished initializing TPU system.\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Finished initializing TPU system.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Found TPU system:\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Found TPU system:\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["physical GPU devises\n","[]\n","physical TPU devises\n","[]\n"]}],"source":["import tensorflow as tf\n","\n","try:\n","  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n","  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n","except ValueError:\n","  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n","\n","tf.config.experimental_connect_to_cluster(tpu)\n","tf.tpu.experimental.initialize_tpu_system(tpu)\n","tpu_strategy = tf.distribute.TPUStrategy(tpu)\n","\n","try:\n","  physical_devices = tf.config.list_physical_devices('GPU')\n","  print(\"physical GPU devises\")\n","  print(physical_devices)\n","except ValueError:\n","  print(\"no GPU devices\")\n","\n","physical_devices = tf.config.list_physical_devices('TPU')\n","print(\"physical TPU devises\")\n","print(physical_devices)\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Sa-IrJS1aRVJ"},"source":["In order to use a GPU with your notebook, select the Runtime > Change runtime type menu, and then set the hardware accelerator dropdown to GPU."]},{"cell_type":"markdown","metadata":{"id":"65MSuHKqNeBZ"},"source":["## More memory\n","\n","With Colab Pro you have the option to access high-memory VMs when they are available, and with Pro+ even more so. To set your notebook preference to use a high-memory runtime, select the Runtime > 'Change runtime type' menu, and then select High-RAM in the Runtime shape dropdown.\n","\n","You can see how much memory you have available at any time by running the following code cell.\n","\n","\n","\n","If the execution result of running the code cell below is \"Not using a high-RAM runtime\", then you can enable a high-RAM runtime via Runtime > Change runtime type in the menu. Then select High-RAM in the Runtime shape dropdown. After, re-execute the code cell.\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"K_6nI-tPdg21","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642532416247,"user_tz":300,"elapsed":129,"user":{"displayName":"Wolfgang Gruen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01742609913198784862"}},"outputId":"7f10ffd5-735b-468c-bd09-48ec30777ae3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Your runtime has 13.6 gigabytes of available RAM\n","\n","Not using a high-RAM runtime\n"]}],"source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"]},{"cell_type":"markdown","metadata":{"id":"BJW8Qi-pPpep"},"source":["## Longer runtimes\n","\n","All Colab runtimes are reset after some period of time (which is faster if the runtime isn't executing code). While Colab Pro subscribers still have limits, these will be roughly twice the limits for non-subscribers, with even more stability for Pro+."]},{"cell_type":"markdown","metadata":{"id":"uLlTRcMM_h0k"},"source":["## Resource limits in Colab Pro\n","\n","Your resources are not unlimited in Colab. To make the most of Colab Pro and Pro+, please avoid using resources when you don't need them. For example, only use a GPU or high-RAM runtime when required, and close Colab tabs when finished.\n"]},{"cell_type":"markdown","metadata":{"id":"mm8FzEidvPs6"},"source":["## Send us feedback!\n","\n","If you have any feedback for us, please let us know. The best way to send feedback is by using the Help > 'Send feedback...' menu. If you encounter usage limits in Colab Pro consider subscribing to Pro+. If you are interested in unlimited pay as you go usage to remove all imposed limits, please do let us know.\n","\n","If you encounter errors or other issues with billing (payments) for Colab Pro or Pro+, please email [colab-billing@google.com](mailto:colab-billing@google.com)."]},{"cell_type":"markdown","metadata":{"id":"qB3bdLe8jkAa"},"source":["## More Resources\n","\n","### Working with Notebooks in Colab\n","- [Overview of Colaboratory](/notebooks/basic_features_overview.ipynb)\n","- [Guide to Markdown](/notebooks/markdown_guide.ipynb)\n","- [Importing libraries and installing dependencies](/notebooks/snippets/importing_libraries.ipynb)\n","- [Saving and loading notebooks in GitHub](https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb)\n","- [Interactive forms](/notebooks/forms.ipynb)\n","- [Interactive widgets](/notebooks/widgets.ipynb)\n","- <img src=\"/img/new.png\" height=\"20px\" align=\"left\" hspace=\"4px\" alt=\"New\"></img>\n"," [TensorFlow 2 in Colab](/notebooks/tensorflow_version.ipynb)\n","\n","<a name=\"working-with-data\"></a>\n","### Working with Data\n","- [Loading data: Drive, Sheets, and Google Cloud Storage](/notebooks/io.ipynb) \n","- [Charts: visualizing data](/notebooks/charts.ipynb)\n","- [Getting started with BigQuery](/notebooks/bigquery.ipynb)\n","\n","### Machine Learning Crash Course\n","These are a few of the notebooks from Google's online Machine Learning course. See the [full course website](https://developers.google.com/machine-learning/crash-course/) for more.\n","- [Intro to Pandas DataFrame](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/pandas_dataframe_ultraquick_tutorial.ipynb)\n","- [Linear regression with tf.keras using synthetic data](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/linear_regression_with_synthetic_data.ipynb)\n","\n","\n","<a name=\"using-accelerated-hardware\"></a>\n","### Using Accelerated Hardware\n","- [TensorFlow with GPUs](/notebooks/gpu.ipynb)\n","- [TensorFlow with TPUs](/notebooks/tpu.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"RFm2S0Gijqo8"},"source":["<a name=\"machine-learning-examples\"></a>\n","\n","## Machine Learning Examples\n","\n","To see end-to-end examples of the interactive machine learning analyses that Colaboratory makes possible, check out these  tutorials using models from [TensorFlow Hub](https://tfhub.dev).\n","\n","A few featured examples:\n","\n","- [Retraining an Image Classifier](https://tensorflow.org/hub/tutorials/tf2_image_retraining): Build a Keras model on top of a pre-trained image classifier to distinguish flowers.\n","- [Text Classification](https://tensorflow.org/hub/tutorials/tf2_text_classification): Classify IMDB movie reviews as either *positive* or *negative*.\n","- [Style Transfer](https://tensorflow.org/hub/tutorials/tf2_arbitrary_image_stylization): Use deep learning to transfer style between images.\n","- [Multilingual Universal Sentence Encoder Q&A](https://tensorflow.org/hub/tutorials/retrieval_with_tf_hub_universal_encoder_qa): Use a machine learning model to answer questions from the SQuAD dataset.\n","- [Video Interpolation](https://tensorflow.org/hub/tutorials/tweening_conv3d): Predict what happened in a video between the first and the last frame.\n"]}]}